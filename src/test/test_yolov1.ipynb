{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test yolov1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path=['/data/ylw/code/pl_cn/src/test', '/home/jiangxing/anaconda3/envs/train/lib/python39.zip', '/home/jiangxing/anaconda3/envs/train/lib/python3.9', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/lib-dynload', '', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/labelme-5.0.1-py3.9.egg', '/data/ylw/code/pl_cn']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.nets.yolov1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msys\u001b[39m.\u001b[39mpath\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m reload\n\u001b[0;32m----> <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myolov1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresnet_yolo\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet50\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.nets.yolov1'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(f'.'))))\n",
    "print(f'{sys.path=}')\n",
    "from importlib import reload\n",
    "from src.nets.yolov1.resnet_yolo import resnet50\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container{width:100% !important;}</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 3, 416, 416])  y.shape=torch.Size([2, 13, 13, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "net = resnet50()\n",
    "x = torch.randn(size=(2, 3, 416, 416))\n",
    "y = net(x)\n",
    "print(f'{x.shape=}  {y.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 3, 416, 416])  y.shape=torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "mb = models.mobilenet_v2(pretrained=False)\n",
    "\n",
    "x = torch.randn(size=(2, 3, 416, 416))\n",
    "y = mb(x)\n",
    "print(f'{x.shape=}  {y.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.nets.yolov1.mobilev2' from '/data/ylw/code/pl_yolo/src/nets/yolov1/mobilev2.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 3, 416, 416])  y.shape=torch.Size([2, 13, 13, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from src.nets.yolov1 import mobilev2\n",
    "# from src.nets.yolov1.mobilev2 import MobileNetV2\n",
    "reload(mobilev2)\n",
    "\n",
    "# mb = mobilev2.MobileNetV2()\n",
    "mb = mobilev2.get_mobilenet_v2()\n",
    "\n",
    "x = torch.randn(size=(2, 3, 416, 416))\n",
    "y = mb(x)\n",
    "print(f'{x.shape=}  {y.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m lr_scheduler\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             mb\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m lr_scheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     optimizer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     T_max\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     eta_min\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m lrs \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mb' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            mb.parameters(),\n",
    "            lr=0.01,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "lr_scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=10, \n",
    "    eta_min=0\n",
    ")\n",
    "\n",
    "lrs = []\n",
    "epochs = 100\n",
    "for epoch in range(epochs): \n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    lr_scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(lrs, color='r')\n",
    "plt.text(0, lrs[0], str(lrs[0]))\n",
    "plt.text(epochs, lrs[-1], str(lrs[-1]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test yolov3 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path=['/data/ylw/code/pl_yolo/src/test', '/home/jiangxing/anaconda3/envs/train/lib/python39.zip', '/home/jiangxing/anaconda3/envs/train/lib/python3.9', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/lib-dynload', '', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages', '/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/labelme-5.0.1-py3.9.egg', '/data/ylw/code/pl_yolo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.dataset.yolov3.datasets' from '/data/ylw/code/pl_yolo/src/dataset/yolov3/datasets.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>.container{width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(f'.'))))\n",
    "print(f'{sys.path=}')\n",
    "from importlib import reload\n",
    "import src.dataset.yolov3.datasets as datasets\n",
    "reload(datasets)\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container{width:100% !important;}</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def xywh2xyxy_np(x):\n",
    "    y = np.zeros_like(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "class ImgAug(object):\n",
    "    def __init__(self, augmentations=[]):\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Unpack data\n",
    "        img, boxes = data\n",
    "\n",
    "        # Convert xywh to xyxy\n",
    "        boxes = np.array(boxes)\n",
    "        boxes[:, 1:] = xywh2xyxy_np(boxes[:, 1:])\n",
    "\n",
    "        # Convert bounding boxes to imgaug\n",
    "        bounding_boxes = BoundingBoxesOnImage(\n",
    "            [BoundingBox(*box[1:], label=box[0]) for box in boxes],\n",
    "            shape=img.shape)\n",
    "\n",
    "        # Apply augmentations\n",
    "        img, bounding_boxes = self.augmentations(\n",
    "            image=img,\n",
    "            bounding_boxes=bounding_boxes)\n",
    "\n",
    "        # Clip out of image boxes\n",
    "        bounding_boxes = bounding_boxes.clip_out_of_image()\n",
    "\n",
    "        # Convert bounding boxes back to numpy\n",
    "        boxes = np.zeros((len(bounding_boxes), 5))\n",
    "        for box_idx, box in enumerate(bounding_boxes):\n",
    "            # Extract coordinates for unpadded + unscaled image\n",
    "            x1 = box.x1\n",
    "            y1 = box.y1\n",
    "            x2 = box.x2\n",
    "            y2 = box.y2\n",
    "\n",
    "            # Returns (x, y, w, h)\n",
    "            boxes[box_idx, 0] = box.label\n",
    "            boxes[box_idx, 1] = ((x1 + x2) / 2)\n",
    "            boxes[box_idx, 2] = ((y1 + y2) / 2)\n",
    "            boxes[box_idx, 3] = (x2 - x1)\n",
    "            boxes[box_idx, 4] = (y2 - y1)\n",
    "\n",
    "        return img, boxes\n",
    "\n",
    "\n",
    "class RelativeLabels(object):\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data):\n",
    "        img, boxes = data\n",
    "        h, w, _ = img.shape\n",
    "        boxes[:, [1, 3]] /= w\n",
    "        boxes[:, [2, 4]] /= h\n",
    "        return img, boxes\n",
    "\n",
    "\n",
    "class AbsoluteLabels(object):\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data):\n",
    "        img, boxes = data\n",
    "        h, w, _ = img.shape\n",
    "        boxes[:, [1, 3]] *= w\n",
    "        boxes[:, [2, 4]] *= h\n",
    "        return img, boxes\n",
    "\n",
    "\n",
    "class PadSquare(ImgAug):\n",
    "    def __init__(self, ):\n",
    "        self.augmentations = iaa.Sequential([\n",
    "            iaa.PadToAspectRatio(\n",
    "                1.0,\n",
    "                position=\"center-center\").to_deterministic()\n",
    "        ])\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data):\n",
    "        img, boxes = data\n",
    "        # Extract image as PyTorch tensor\n",
    "        img = transforms.ToTensor()(img)\n",
    "\n",
    "        bb_targets = torch.zeros((len(boxes), 6))\n",
    "        bb_targets[:, 1:] = transforms.ToTensor()(boxes)\n",
    "\n",
    "        return img, bb_targets\n",
    "\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, data):\n",
    "        img, boxes = data\n",
    "        img = F.interpolate(img.unsqueeze(0), size=self.size, mode=\"nearest\").squeeze(0)\n",
    "        return img, boxes\n",
    "\n",
    "class DefaultAug(ImgAug):\n",
    "    def __init__(self, ):\n",
    "        self.augmentations = iaa.Sequential([\n",
    "            iaa.Sharpen((0.0, 0.1)),\n",
    "            iaa.Affine(rotate=(-0, 0), translate_percent=(-0.1, 0.1), scale=(0.8, 1.5)),\n",
    "            iaa.AddToBrightness((-60, 40)),\n",
    "            iaa.AddToHue((-10, 10)),\n",
    "            iaa.Fliplr(0.5),\n",
    "        ])\n",
    "\n",
    "\n",
    "DEFAULT_TRANSFORMS = transforms.Compose([\n",
    "    AbsoluteLabels(),\n",
    "    PadSquare(),\n",
    "    RelativeLabels(),\n",
    "    ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/ylw/code/pl_yolo/data/yolov1/voc2007.txt', '/data/ylw/code/pl_yolo/data/yolov1/voc2012.txt']\n",
      "[------------]  img.shape=(375, 500, 3)  boxes.shape=torch.Size([1, 4])[------------]  img.shape=(322, 500, 3)  boxes.shape=torch.Size([2, 4])\n",
      "[------------]  img.shape=(375, 500, 3)  boxes.shape=torch.Size([3, 4])[------------]  img.shape=(387, 500, 3)  boxes.shape=torch.Size([1, 4])\n",
      "\n",
      "\n",
      "Could not apply transform.\n",
      "Could not apply transform.Could not apply transform.\n",
      "\n",
      "Could not apply transform.\n",
      "[------------]  img.shape=(499, 333, 3)  boxes.shape=torch.Size([1, 4])\n",
      "[------------]  img.shape=(500, 375, 3)  boxes.shape=torch.Size([1, 4])[------------]  img.shape=(375, 500, 3)  boxes.shape=torch.Size([3, 4])\n",
      "\n",
      "Could not apply transform.\n",
      "[------------]  img.shape=(404, 500, 3)  boxes.shape=torch.Size([1, 4])Could not apply transform.\n",
      "\n",
      "Could not apply transform.[------------]  img.shape=(375, 500, 3)  boxes.shape=torch.Size([2, 4])\n",
      "\n",
      "Could not apply transform.Could not apply transform.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/data/ylw/code/pl_yolo/src/dataset/yolov3/datasets.py\", line 154, in collate_fn\n    paths, imgs, bb_targets = list(zip(*batch))\nValueError: not enough values to unpack (expected 3, got 0)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mListDataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     data_dir, \n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     list_file, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     dataset, \n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     shuffle \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     collate_fn\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mcollate_fn\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mbatch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_yolo/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1251\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/train/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jiangxing/anaconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/data/ylw/code/pl_yolo/src/dataset/yolov3/datasets.py\", line 154, in collate_fn\n    paths, imgs, bb_targets = list(zip(*batch))\nValueError: not enough values to unpack (expected 3, got 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[------------]  img.shape=(333, 500, 3)  boxes.shape=torch.Size([2, 4])\n",
      "[------------]  img.shape=(350, 500, 3)  boxes.shape=torch.Size([3, 4])\n",
      "[------------]  img.shape=(500, 375, 3)  boxes.shape=torch.Size([2, 4])Could not apply transform."
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "data_dir = f'/data/ylw/datasets/voc/VOC2007/JPEGImages'\n",
    "list_file = [\n",
    "    f'/data/ylw/code/pl_yolo/data/yolov1/voc2007.txt',\n",
    "    f'/data/ylw/code/pl_yolo/data/yolov1/voc2012.txt'\n",
    "]\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "dataset = datasets.ListDataset(\n",
    "    data_dir, \n",
    "    list_file, \n",
    "    img_size=416, \n",
    "    multiscale=True, \n",
    "    transform=torchvision.transforms.Compose([\n",
    "        # AbsoluteLabels(),\n",
    "        # DefaultAug(),\n",
    "        # PadSquare(),\n",
    "        # RelativeLabels(),\n",
    "        ToTensor(),\n",
    "    ])\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    shuffle = False, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    num_workers = 4, \n",
    "    pin_memory=True,\n",
    "    drop_last=True, \n",
    "    collate_fn=dataset.collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(loader):\n",
    "    print(f'{batch}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug][0]: FileStream started : /data/ylw/code/pl_yolo/src/test/test.log : t=1.07\n",
      "[Debug][0]: Notebook created : /data/ylw/code/pl_yolo/src/test/test.ipynb : t=1.11\n"
     ]
    }
   ],
   "source": [
    "import tensorwatch as tw\n",
    "import time\n",
    "\n",
    "# streams will be stored in test.log file\n",
    "w = tw.Watcher(filename='test.log')\n",
    "\n",
    "# create a stream for logging\n",
    "s = w.create_stream(name='metric1')\n",
    "\n",
    "# generate Jupyter Notebook to view real-time streams\n",
    "w.make_notebook()\n",
    "\n",
    "for i in range(1000):\n",
    "    # write x,y pair we want to log\n",
    "    s.write((i, i*i))\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug][0]: FileStream started : /data/ylw/code/pl_cn/src/test/test.log : t=0.73\n",
      "[Debug][0]: Notebook created : /data/ylw/code/pl_cn/src/test/test.ipynb : t=0.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# write x,y pair we want to log\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     s\u001b[39m.\u001b[39mwrite((i, i\u001b[39m*\u001b[39mi)) \n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/ylw/code/pl_cn/src/test/test_yolov1.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorwatch as tw\n",
    "import time\n",
    " \n",
    "# streams will be stored in test.log file\n",
    "w = tw.Watcher(filename='test.log')\n",
    " \n",
    "# create a stream for logging\n",
    "s = w.create_stream(name='metric1')\n",
    " \n",
    "# generate Jupyter Notebook to view real-time streams\n",
    "w.make_notebook()\n",
    " \n",
    "for i in range(1000):\n",
    "    # write x,y pair we want to log\n",
    "    s.write((i, i*i)) \n",
    " \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d740c7646e63427e6191f8164d347786ef6ce3d268dc00d8555a471847f63fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
